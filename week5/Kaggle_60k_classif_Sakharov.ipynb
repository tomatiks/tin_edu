{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorboard import summary as summary_lib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm_notebook,tqdm_pandas,tqdm\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import nltk\n",
    "\n",
    "from tf_metrics import tf_metrics\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm, ...)`.\n"
     ]
    }
   ],
   "source": [
    "tqdm_pandas(tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('60k-classes-text-classification/train.csv',sep=',')\n",
    "df_test = pd.read_csv('60k-classes-text-classification/test.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>How can you make physics easy to learn?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>What was your first sexual experience?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>What would a Trump presidency mean for current...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>What does manipulation mean?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>What does manipulation means?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Why are so many Quora users posting questions ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Why do people ask Quora questions which can be...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Why do rockets look white?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Why are rockets and boosters painted white?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>How should I prepare for CA final law?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>How one should know that he/she completely pre...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>What are some special cares for someone with a...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>How can I keep my nose from getting stuffy at ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>What Game of Thrones villain would be the most...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>What Game of Thrones villain would you most li...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>How do we prepare for UPSC?</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>How do I prepare for civil service?</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>What are some examples of products that can be...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>What are some of the products made from crude ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>How do I make friends.</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>How to make friends ?</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150802</th>\n",
       "      <td>150802</td>\n",
       "      <td>What is the work of an executive recruiter like?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150803</th>\n",
       "      <td>150803</td>\n",
       "      <td>Does Tango currently offer new employees stock...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150804</th>\n",
       "      <td>150804</td>\n",
       "      <td>Who colonized Egypt? How was it colonized?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150805</th>\n",
       "      <td>150805</td>\n",
       "      <td>Why are there so many low quality questions in...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150806</th>\n",
       "      <td>150806</td>\n",
       "      <td>Why does a CPU have so many VCC/VSS pins?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150807</th>\n",
       "      <td>150807</td>\n",
       "      <td>What is original jurisdiction?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150808</th>\n",
       "      <td>150808</td>\n",
       "      <td>People born on 26 sep 1994 under Rohini naksha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150809</th>\n",
       "      <td>150809</td>\n",
       "      <td>Very strange and weird things happen in my ear...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150810</th>\n",
       "      <td>150810</td>\n",
       "      <td>Linkedin and \"Profile Not Found\". Is LinkedIn ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150811</th>\n",
       "      <td>150811</td>\n",
       "      <td>What does polarity of molecules mean?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150812</th>\n",
       "      <td>150812</td>\n",
       "      <td>Why don’t we use \"a\" when talking about techno...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150813</th>\n",
       "      <td>150813</td>\n",
       "      <td>What is third pricing model?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150814</th>\n",
       "      <td>150814</td>\n",
       "      <td>From where can I get the F-code for purchasing...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150815</th>\n",
       "      <td>150815</td>\n",
       "      <td>What is bca AI vs btech AI if I want to pursue...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150816</th>\n",
       "      <td>150816</td>\n",
       "      <td>On a freeway where an accident has occurred on...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150817</th>\n",
       "      <td>150817</td>\n",
       "      <td>What are the pros and cons of cultural relativ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150818</th>\n",
       "      <td>150818</td>\n",
       "      <td>Can I work remotely for a US-based company as ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150819</th>\n",
       "      <td>150819</td>\n",
       "      <td>Can we upgrade from Windows 8.1 to Windows 10?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150820</th>\n",
       "      <td>150820</td>\n",
       "      <td>What does an IDA pay scale basic pay of 9,760 ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150821</th>\n",
       "      <td>150821</td>\n",
       "      <td>Which is better for use in slabs : PPC/PSC or ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150822</th>\n",
       "      <td>150822</td>\n",
       "      <td>What if Sourav Ganguly played badminton instea...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150823</th>\n",
       "      <td>150823</td>\n",
       "      <td>What are some alternatives to feed demon?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150824</th>\n",
       "      <td>150824</td>\n",
       "      <td>Renaissance Technologies: How can I invest wit...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150825</th>\n",
       "      <td>150825</td>\n",
       "      <td>What countries do not have a democracy?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150826</th>\n",
       "      <td>150826</td>\n",
       "      <td>Are there separate rooms for every student in ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150827</th>\n",
       "      <td>150827</td>\n",
       "      <td>Where can I get genuine pest control service i...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150828</th>\n",
       "      <td>150828</td>\n",
       "      <td>Harvard College Courses: What is general shopp...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150829</th>\n",
       "      <td>150829</td>\n",
       "      <td>How does America see the rest of the world?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150830</th>\n",
       "      <td>150830</td>\n",
       "      <td>How do we convince my boyfriend's parents for ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150831</th>\n",
       "      <td>150831</td>\n",
       "      <td>Why should I buy gold coins from bank?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150832 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                               text  labels\n",
       "0            0  Astrology: I am a Capricorn Sun Cap moon and c...       0\n",
       "1            1  I'm a triple Capricorn (Sun, Moon and ascendan...       0\n",
       "2            2                     How can I be a good geologist?       1\n",
       "3            3          What should I do to be a great geologist?       1\n",
       "4            4        How do I read and find my YouTube comments?       2\n",
       "5            5             How can I see all my Youtube comments?       2\n",
       "6            6               What can make Physics easy to learn?       3\n",
       "7            7            How can you make physics easy to learn?       3\n",
       "8            8        What was your first sexual experience like?       4\n",
       "9            9             What was your first sexual experience?       4\n",
       "10          10  What would a Trump presidency mean for current...       5\n",
       "11          11  How will a Trump presidency affect the student...       5\n",
       "12          12                       What does manipulation mean?       6\n",
       "13          13                      What does manipulation means?       6\n",
       "14          14  Why are so many Quora users posting questions ...       7\n",
       "15          15  Why do people ask Quora questions which can be...       7\n",
       "16          16                         Why do rockets look white?       8\n",
       "17          17        Why are rockets and boosters painted white?       8\n",
       "18          18             How should I prepare for CA final law?       9\n",
       "19          19  How one should know that he/she completely pre...       9\n",
       "20          20  What are some special cares for someone with a...      10\n",
       "21          21  How can I keep my nose from getting stuffy at ...      10\n",
       "22          22  What Game of Thrones villain would be the most...      11\n",
       "23          23  What Game of Thrones villain would you most li...      11\n",
       "24          24                        How do we prepare for UPSC?      12\n",
       "25          25                How do I prepare for civil service?      12\n",
       "26          26  What are some examples of products that can be...      13\n",
       "27          27  What are some of the products made from crude ...      13\n",
       "28          28                             How do I make friends.      14\n",
       "29          29                              How to make friends ?      14\n",
       "...        ...                                                ...     ...\n",
       "150802  150802   What is the work of an executive recruiter like?      -1\n",
       "150803  150803  Does Tango currently offer new employees stock...      -1\n",
       "150804  150804         Who colonized Egypt? How was it colonized?      -1\n",
       "150805  150805  Why are there so many low quality questions in...      -1\n",
       "150806  150806          Why does a CPU have so many VCC/VSS pins?      -1\n",
       "150807  150807                     What is original jurisdiction?      -1\n",
       "150808  150808  People born on 26 sep 1994 under Rohini naksha...      -1\n",
       "150809  150809  Very strange and weird things happen in my ear...      -1\n",
       "150810  150810  Linkedin and \"Profile Not Found\". Is LinkedIn ...      -1\n",
       "150811  150811              What does polarity of molecules mean?      -1\n",
       "150812  150812  Why don’t we use \"a\" when talking about techno...      -1\n",
       "150813  150813                       What is third pricing model?      -1\n",
       "150814  150814  From where can I get the F-code for purchasing...      -1\n",
       "150815  150815  What is bca AI vs btech AI if I want to pursue...      -1\n",
       "150816  150816  On a freeway where an accident has occurred on...      -1\n",
       "150817  150817  What are the pros and cons of cultural relativ...      -1\n",
       "150818  150818  Can I work remotely for a US-based company as ...      -1\n",
       "150819  150819     Can we upgrade from Windows 8.1 to Windows 10?      -1\n",
       "150820  150820  What does an IDA pay scale basic pay of 9,760 ...      -1\n",
       "150821  150821  Which is better for use in slabs : PPC/PSC or ...      -1\n",
       "150822  150822  What if Sourav Ganguly played badminton instea...      -1\n",
       "150823  150823          What are some alternatives to feed demon?      -1\n",
       "150824  150824  Renaissance Technologies: How can I invest wit...      -1\n",
       "150825  150825            What countries do not have a democracy?      -1\n",
       "150826  150826  Are there separate rooms for every student in ...      -1\n",
       "150827  150827  Where can I get genuine pest control service i...      -1\n",
       "150828  150828  Harvard College Courses: What is general shopp...      -1\n",
       "150829  150829        How does America see the rest of the world?      -1\n",
       "150830  150830  How do we convince my boyfriend's parents for ...      -1\n",
       "150831  150831             Why should I buy gold coins from bank?      -1\n",
       "\n",
       "[150832 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60416"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['labels']!=-1]['labels'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'].apply(len).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prep_tags(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    # Убираем лишние символы\n",
    "    #text = re.sub(r'[;,]',r' ',text).strip()\n",
    "    text = re.sub(r'[^\\w\\s\\.]',r'',text).strip()   \n",
    "    #text = [token.text for token in razdel.tokenize(text)]\n",
    "    # Делаем лемматизацию       \n",
    "#     text = [lemma for lemma in mystem.lemmatize(text) if not lemma.isspace() and lemma not in sw_ru\n",
    "#             and lemma.strip() not in ['.','..','...']]\n",
    "    \n",
    "    \n",
    "    for item in mystem.analyze(text):\n",
    "      #  print(item)\n",
    "        token = None\n",
    "        if item.get('analysis'):\n",
    "            lemma = item['analysis'][0]['lex']\n",
    "            pos = re.split('[=,]', item['analysis'][0]['gr'])[0]\n",
    "            #and lemma not in sw_ru\n",
    "            if not lemma.isspace()  and lemma.strip() not in ['.','..','...'] and lemma not in sw_ru:\n",
    "     \n",
    "                token = f'{lemma}_{upos_map[pos]}'\n",
    "        else:\n",
    "            lem_text = item[\"text\"]\n",
    "            if not lem_text.isspace() and lem_text.strip() not in ['.','..','...'] and lem_text not in sw_ru:\n",
    "            \n",
    "                token = f'{lem_text}_UNKN'\n",
    "            \n",
    "        if token:    \n",
    "            result.append(token)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Лемматизатор неправильно разбивает слова с дефисом, поэтому исправляем это\n",
    "#     if '-' in text:\n",
    "#         for l in range(len(text)):\n",
    "#             if text[l] == '-':\n",
    "#                 text[l] = f'{text[l-1]}-{text[l+1]}'\n",
    "#                 text[l-1] = text[l+1] = text[l]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dmitriy/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_ru = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "upos_map = {'A':'ADJ','ADV':'ADV','ADVPRO':'ADV','ANUM':'ADJ','APRO':'DET','COM':'ADJ','CONJ':'SCON','INTJ':'INTJ','NONLEX':'X','NUM':'NUM','PART':'PART','PR':'ADP','S':'NOUN','SPRO':'PRON','UNKN':'X' ,'V':'VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://vectors.nlpl.eu/repository/11/185.zip\n",
    "word2vec = KeyedVectors.load_word2vec_format('w2v/tayga_upos_skipgram_300_2_2019.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09c92d5e5a6498bb106afdcb87a428d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function text_prep_tags at 0x7f5429300730>,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_v = CountVectorizer(tokenizer=text_prep_tags)\n",
    "count_v.fit(tqdm_notebook(pd.concat([df_train['text'],df_test['text']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150832/150832 [00:12<00:00, 12355.47it/s]\n",
      "100%|██████████| 58788/58788 [00:04<00:00, 11760.04it/s]\n"
     ]
    }
   ],
   "source": [
    "train_token_text = df_train['text'].progress_apply(text_prep_tags)\n",
    "test_token_text = df_test['text'].progress_apply(text_prep_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150832/150832 [00:00<00:00, 230681.76it/s]\n",
      "100%|██████████| 58788/58788 [00:00<00:00, 249081.00it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ids = train_token_text.progress_apply(lambda x: list(map(lambda y: count_v.vocabulary_[y] +1 , x)))\n",
    "test_ids = test_token_text.progress_apply(lambda x: list(map(lambda y: count_v.vocabulary_[y] +1 , x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (150832, 60)\n",
      "x_train shape: (58788, 60)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(count_v.vocabulary_)\n",
    "sentence_size = 60\n",
    "embedding_size = 300\n",
    "\n",
    "\n",
    "# первые индексы в словаре зарезервированы за специальными токенами \n",
    "# для паддинга, начала предложения, и для слов которые не вошли в словарь\n",
    "pad_id = 0\n",
    "start_id = 1\n",
    "oov_id = 2\n",
    "index_offset = 2\n",
    "\n",
    "\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "train_ids = sequence.pad_sequences(train_ids, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "\n",
    "print(\"x_train shape:\", train_ids.shape)\n",
    "test_ids = sequence.pad_sequences(test_ids, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "\n",
    "print(\"x_train shape:\", test_ids.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5241, 22539,  3913, ...,     0,     0,     0],\n",
       "       [22876,  2472, 46991, ...,     0,     0,     0],\n",
       "       [22149,  8670, 22539, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [22149, 14736,  3987, ...,     0,     0,     0],\n",
       "       [22149, 14685, 49656, ...,     0,     0,     0],\n",
       "       [50055, 41721, 22539, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_triplet = df_train.copy()\n",
    "df_train_triplet['anchor'] = pd.Series(train_ids.tolist())\n",
    "df_train_triplet.drop(['index','text'],inplace=True,axis=1)\n",
    "\n",
    "df_train_triplet_classes = df_train_triplet[df_train_triplet['labels']!=-1]\n",
    "df_train_triplet_1 = df_train_triplet[df_train_triplet['labels']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120832, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_triplet_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_triplet_classes = df_train_triplet_classes.reset_index().sort_values(['labels','index'])\n",
    "df_train_triplet_classes['positive'] = df_train_triplet_classes.reset_index().sort_values(['labels','index'],ascending=[True,False])['anchor'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_triplet_classes = df_train_triplet_classes[df_train_triplet_classes['index']%2==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_triplet = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_triplet_classes.sample(replace=True,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136547    [42776, 13304, 32595, 2472, 34534, 30295, 2773...\n",
       "147930    [22149, 14685, 3525, 28083, 46305, 43644, 2369...\n",
       "125199    [50055, 14843, 34406, 16867, 18562, 45799, 181...\n",
       "Name: anchor, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample_1(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_classes(label):\n",
    "    df = df_train_triplet_classes[df_train_triplet_classes['labels']!=label]['anchor']\n",
    "    return df.sample(12,replace=True).values\n",
    "def get_sample_1():\n",
    "    df = df_train_triplet_1['anchor']\n",
    "    return df.sample(3,replace=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c65f2ec69b45edb28565f130bfd70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for triplet in tqdm_notebook(df_train_triplet_classes.itertuples(index=False)):\n",
    "    trip =  {'anchor': [triplet.anchor]*15, 'positive': [triplet.positive]*15, 'negative': \n",
    "            list(get_sample_classes(triplet.labels))+list(get_sample_1())}\n",
    "\n",
    "    df = pd.DataFrame(trip)\n",
    "    new_df_triplet = new_df_triplet.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_triplet = new_df_triplet.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_triplet.to_json('triplet_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(906240, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_triplet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def input_fn(x, labels, params, is_training):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, labels))\n",
    "\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(buffer_size=params['buffer_size'])\n",
    "        dataset = dataset.repeat(count=params['num_epochs'])\n",
    "\n",
    "    dataset = dataset.batch(params['batch_size'])\n",
    "    dataset = dataset.prefetch(buffer_size=2)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(shape=None, dtype=None, partition_info=None):    \n",
    "    vocab_dict = count_v.vocabulary_\n",
    "    embedding_matrix = np.random.uniform(-1, 1, size=(vocab_size+1, embedding_size))\n",
    "    num_loaded = 0\n",
    "    for w, i in vocab_dict.items():\n",
    "        v = None\n",
    "        try:\n",
    "            v = word2vec[w]\n",
    "        except KeyError: # не нашли такой токен в словаре\n",
    "                pass\n",
    "        if v is not None :\n",
    "            embedding_matrix[i+1] = v\n",
    "            num_loaded += 1\n",
    "   \n",
    "    embedding_matrix = embedding_matrix.astype(np.float32)\n",
    "    embedding_matrix[0] = np.zeros(300)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):  \n",
    "    \n",
    "    # Compute predictions.\n",
    "    net = params['net']\n",
    "    \n",
    "    encoded_features = {}  \n",
    "    \n",
    "    with tf.variable_scope('encoder'):\n",
    "        encoded_features['anchor'] = net(features['anchor'])\n",
    "    with tf.variable_scope('encoder', reuse=True):\n",
    "        encoded_features['positive'] = net(features['positive'])\n",
    "    with tf.variable_scope('encoder', reuse=True):\n",
    "        encoded_features['negative'] = net(features['negative'])\n",
    "    \n",
    "    \n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    # Compute loss.\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # Compute evaluation metrics.\n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                               predictions=predicted_classes,\n",
    "                               name='acc_op')\n",
    "    f1 = tf_metrics.f1(labels=labels,\n",
    "                               predictions=predicted_classes,num_classes=3,average='micro')\n",
    "    \n",
    "    metrics = {'accuracy': accuracy,'f1':f1}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "    \n",
    "    # Compute evaluation\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "    \n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    \n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_fn(features):\n",
    "    inputs = tf.contrib.layers.embed_sequence(\n",
    "        features['x'], vocab_size, embedding_size,\n",
    "        initializer=initializer, trainable=False)\n",
    "\n",
    "    conv = tf.layers.conv1d(\n",
    "        inputs=inputs,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    print(conv.get_shape())\n",
    "    # Global Max Pooling\n",
    "    pool = tf.reduce_max(input_tensor=conv, axis=1)\n",
    "    print(pool.get_shape())\n",
    "    hidden = tf.layers.dense(inputs=pool, units=100, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=hidden, units=64)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ids,X_val_ids,y_train,y_val = train_test_split(train_ids,X_train['label'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final save to csv\n",
    "submit = pd.read_csv('60k-classes-text-classification/sample_submission.csv', encoding='utf-8',sep=',',index_col='index')\n",
    "submit['labels'] = -1\n",
    "submit.to_csv('random.csv', encoding='utf-8',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
