{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1) Какую роль выполняет функция активации в полносвязной нейросети? Также нужно пояснить, почему стакать несколько подряд идущих полносвязных слоев без активации не является хорошей практикой.* **0.5 балла**\n",
    "\n",
    "*2) Допустим у вас есть MLP (\"multi layer perceptron\" или полносвязная нейросеть) с 10-ю входными нейронами, за ними 50 нейронов в скрытом слое, на выходе 3 нейрона. Все нейроны снабжены функцией активации ReLU.* **1 балл**\n",
    "- Какова размерность матрицы $X$ на входе, если обучение проводится батчами. Размер батча $batch\\_size$\n",
    "- Какова размерность матрицы весов скрытого слоя $W_h$ и какова размерность вектора байеса $b_h$ этого скрытого слоя?\n",
    "- Какова размерность матрицы весов выходного слоя $W_o$ и какова размерность вектора байеса $b_o$ выходного слоя?\n",
    "- Какова размерность выходной матрицы $Y$?\n",
    "- Напишите как выглядит функция, которая считает выходную матрицу $Y$ как функцию от $X$, $W_h$, $W_o$, $b_h$, $b_o$.\n",
    "\n",
    "*3) Как устроено автоматическое дифференцирование в Tensorflow?* **0.5 балла**\n",
    "- Используются ли символьные вычисления?\n",
    "- Используется ли численное дифференцирование?\n",
    "- Сколько проходов по графу вычислений необходимо совершить,\n",
    "  чтобы посчитать градиенты для каждого параметра в Tensorflow?\n",
    "  \n",
    "*4) Что такое \"backpropagation\" и для чего он нужен. Чем он отличается от алгоритма градиентного спуска?* **0.5 балла**\n",
    "\n",
    "*5) Расскажите в чем отличия между mini-batch, batch, stochastic gradient descent. Какой из этих алгоритмов самый популярный и почему.* **0.5 балла**\n",
    "\n",
    "*6) Можно ли инициализировать первоначально все параметры обучаемой модели MLP единицами? А нулями? Поясните ваш ответ. Можно ли инициализировать нулями параметры $b_o$, $b_h$ из задачи №2?* **0.5 балла**\n",
    "\n",
    "*7) Вывести лосс-функцию кросс-энтропии из правдоподобия и из теории информации.* **0.5 балла**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические ответы\n",
    "\n",
    "1)Функция активации добавляет нелинейность в модель, делает общую функцию сети нелинейной.<br>\n",
    "Если стакнуть несколько слоев без активации, то модель останется линейной, просто будет больше параметров у <br>модели, но она не сможет работать для сложных данных.<br>\n",
    "<br>\n",
    "2)<br>\n",
    "-$X$ =  [10,batch_size]<br>\n",
    "-$W_h$ = [49,10] ,  $b_h$ = [3] размерность вектора весов, сам нейрон смещения равен 1<br>\n",
    "-$W_o$ = [3,49] ,  $b_o$ = в выходном слое не может быть нейрона смещения<br>\n",
    "-$Y$ =  [3,batch_size]<br>\n",
    "-$Y$  = $W_o$$*$$W_h$$*$$X$ + $b_h$<br>\n",
    "<br>\n",
    "3)<br>\n",
    "-символьные вычисления = нет<br>\n",
    "-численное дифференцирование = нет<br>\n",
    "-один проход<br>\n",
    "<br>\n",
    "4)backpropagation - это метод обратного распространения ошибки в графе вычислений нейросети.<br>\n",
    "На выходе сети считается градиент ошибки и дальше с помощью вычисления частных произовдных в узлах <br>\n",
    "графа вычислений градиент проходит глубже и для каждого веса определяется градиент на который его нужно скорректировать<br>\n",
    "Градиентный спуск позволяет итеративно уменьшать ошибку путем коррекции весов ф-ии на величину градиента в сторону<br> его убывания. В нейросетях используется для нахождения изначального градиента ошибки на выходе нейросети<br><br>\n",
    "5)batch = градиент вычисляется для всего набора данных и обновляет веса только 1 раз за 1 проход по всем данным, зато самый точный<br>\n",
    "mini-batch = градиент считается для небольшой части данных и каждый раз обновляет веса <br>\n",
    "stochastic = считает градиент для каждого экземпляра данных и каждый раз обновляет веса <br>\n",
    "stochastic используется чаще всего, т.к. производит обучение быстрее остальных вариантов, при этом при небольшом <br>learning rate обеспечивает хорошую сходимость <br><br>\n",
    "6) Можно инициализировать и 1 и 0 , но в таком случае все веса в слое будут изменяться одинаково и <br>\n",
    "модель получится слабая. Обычно веса инициализируют случайными значениями из определенных диапазонов, но <br>\n",
    "разными значениями.<br>\n",
    "параметры $b_o$, $b_h$  нельзя инициализировать нулями, так как нейроны смещения всегда равны 1<br>\n",
    "7)<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Первые шаги с TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxiIKhP4E2Zr"
   },
   "source": [
    "[Описание данных](https://developers.google.com/machine-learning/crash-course/california-housing-data-description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVFf5asKE2Zt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    "Подгружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ivCDWnwE2Zx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11437</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>-114.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7223</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16194</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "11437     -114.3      34.2                15.0       5612.0          1283.0   \n",
       "5338      -114.5      34.4                19.0       7650.0          1901.0   \n",
       "7223      -114.6      33.7                17.0        720.0           174.0   \n",
       "16194     -114.6      33.6                14.0       1501.0           337.0   \n",
       "1288      -114.6      33.6                20.0       1454.0           326.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "11437      1015.0       472.0            1.5                66.9  \n",
       "5338       1129.0       463.0            1.8                80.1  \n",
       "7223        333.0       117.0            1.7                85.7  \n",
       "16194       515.0       226.0            3.2                73.4  \n",
       "1288        624.0       262.0            1.9                65.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index)\n",
    ")\n",
    "\n",
    "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
    "california_housing_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## EDA\n",
    "\n",
    "Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     17000.0     17000.0        17000.0             17000.0  \n",
       "mean       1429.6       501.2            3.9               207.3  \n",
       "std        1147.9       384.5            1.9               116.0  \n",
       "min           3.0         1.0            0.5                15.0  \n",
       "25%         790.0       282.0            2.6               119.4  \n",
       "50%        1167.0       409.0            3.5               180.4  \n",
       "75%        1721.0       605.2            4.8               265.0  \n",
       "max       35682.0      6082.0           15.0               500.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr6wYl2bt2Ep",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Первая модель\n",
    "\n",
    "В этом задании требуется предсказать стоимовть жилья (`median_house_value`).\n",
    "\n",
    "Мы будем делать это с помощью [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) и [tf estimators](https://www.tensorflow.org/get_started/estimator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMl3qrU5MGV6"
   },
   "source": [
    "### 1. Определяем target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1NvvNkH8Kbt"
   },
   "outputs": [],
   "source": [
    "targets = california_housing_dataframe[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0IztwdK2f3F"
   },
   "source": [
    "### 2. Определяем входы в модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5M5j6xSCHxx"
   },
   "source": [
    "С помощью [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) и [Feature columns](https://www.tensorflow.org/guide/feature_columns) мы с легкостью определяем, как данные будут подаваться в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKZ9zNcHJtwc"
   },
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \n",
    "    # ключ total_rooms присутствует в features\n",
    "    features = {key: np.array(value) for key, value in dict(features).items()}                                           \n",
    " \n",
    "    ds = tf.data.Dataset.from_tensor_slices((features, targets))\n",
    "    # будем выдавать данные батчами в течение num_epochs эпох\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    if shuffle:\n",
    "        # делаем шафл только во время обучения\n",
    "        # сможете ответить, зачем нужен шафл данных?\n",
    "        ds = ds.shuffle(buffer_size=10000)\n",
    "\n",
    "    return ds\n",
    "\n",
    "my_feature = california_housing_dataframe[[\"total_rooms\"]]\n",
    "# по ключу \"total_rooms\" feature_column будет вытаскивать из tf.data.Dataset нужные фичи\n",
    "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\", shape=(1,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_rooms': array([5612., 7650.,  720., ..., 2677., 2672., 1820.])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: np.array(value) for key, value in dict(my_feature).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'total_rooms': <tf.Tensor: id=751697, shape=(1,), dtype=float64, numpy=array([2587.])>}, <tf.Tensor: id=751698, shape=(1,), dtype=float64, numpy=array([88.6])>)\n"
     ]
    }
   ],
   "source": [
    "for i in my_input_fn(california_housing_dataframe[['total_rooms']],targets):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4M-rTFHL2UkA"
   },
   "source": [
    "### 3. Определяем Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "my_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "# посмотрите, какие аргументы принимает LinearRegressor\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=my_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YS50CQb2ooO"
   },
   "source": [
    "### 4. Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5M-Kt6w8U803"
   },
   "outputs": [],
   "source": [
    "_ = linear_regressor.train(\n",
    "    input_fn = lambda: my_input_fn(my_feature, targets),\n",
    "    steps=100  # 1 step -- это проход по одному батчу\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Nwxqxlx2sOv"
   },
   "source": [
    "### 5. Считаем качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (on training data): 55522.875\n",
      "Root Mean Squared Error (on training data): 235.633\n"
     ]
    }
   ],
   "source": [
    "prediction_input_fn = lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)\n",
    "# питоновский генератор\n",
    "predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "\n",
    "# переводим в numpy\n",
    "predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "# считаем метрики\n",
    "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
    "root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "\n",
    "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
    "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZWF67uv0HTG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Перебор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgSMeD5UU81N"
   },
   "outputs": [],
   "source": [
    "def train_model(learning_rate, num_epochs, batch_size, input_feature=\"total_rooms\"):\n",
    "\n",
    "    my_feature_data = california_housing_dataframe[[input_feature]]\n",
    "    targets = california_housing_dataframe[\"median_house_value\"]\n",
    "\n",
    "    # Create feature columns.\n",
    "    feature_columns = [tf.feature_column.numeric_column(input_feature, shape=(1,))]\n",
    "\n",
    "    # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size, num_epochs=num_epochs)\n",
    "    prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "    # Create a linear regressor object.\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "    linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    linear_regressor.train(input_fn=training_input_fn)\n",
    "\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "    root_mean_squared_error = np.sqrt(metrics.mean_squared_error(predictions, targets))\n",
    "\n",
    "    print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kg8A4ArBU81Q"
   },
   "source": [
    "## Задание 1 (2 балла)\n",
    "\n",
    "Попробуйте поиграть с гиперпараметрами и достигнуть $RMSE \\leq 180$\n",
    "\n",
    "Также можно попробовать:\n",
    "1. Другой оптимайзер ([здесь](https://www.tensorflow.org/api_docs/python/tf/train) можно посмотреть, какие бывают)\n",
    "2. Комбинацию фичей (**feature_columns** -- это list, в котором несколько tf.feature_column.numeric_column)\n",
    "3. Поиграть с аргументами модели (посмотрите, какие аргументы есть у LinearRegressor)\n",
    "\n",
    "p.s.\n",
    "Попробуйте переписать функцию `train_model`, чтобы было удобней изменять параметры модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "UzoZUSdLIolF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Final RMSE (on training data): 169.49\n"
     ]
    }
   ],
   "source": [
    "# пример обучения модели\n",
    "train_model(\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=2,\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(learning_rate, num_epochs, batch_size, input_feature=\"total_rooms\"):\n",
    "\n",
    "    my_feature_data = california_housing_dataframe[[input_feature]]\n",
    "    targets = california_housing_dataframe[\"median_house_value\"]\n",
    "\n",
    "    # Create feature columns.\n",
    "    feature_columns = [tf.feature_column.numeric_column(input_feature, shape=(1,))]\n",
    "\n",
    "    # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size, num_epochs=num_epochs)\n",
    "    prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "    # Create a linear regressor object.\n",
    "    my_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "    linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    linear_regressor.train(input_fn=training_input_fn)\n",
    "\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "    root_mean_squared_error = np.sqrt(metrics.mean_squared_error(predictions, targets))\n",
    "\n",
    "    print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Final RMSE (on training data): 168.43\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    learning_rate=0.00001,\n",
    "    num_epochs=3,\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpV-uF_cBCBU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Задание 2 (2 балла)\n",
    "\n",
    "Попробуйте подать в модель другие фичи и достигнуть $RMSE \\leq 170$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(learning_rate, num_epochs, batch_size, input_features=[\"total_rooms\"]):\n",
    "\n",
    "    my_feature_data = california_housing_dataframe[input_features]\n",
    "    targets = california_housing_dataframe[\"median_house_value\"]\n",
    "\n",
    "    # Create feature columns.\n",
    "    \n",
    "    feature_columns = [tf.feature_column.numeric_column(input_feature, shape=(1,)) for input_feature in input_features]\n",
    "\n",
    "    # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size, num_epochs=num_epochs)\n",
    "    prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "    # Create a linear regressor object.\n",
    "    my_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "    linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    linear_regressor.train(input_fn=training_input_fn)\n",
    "\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "    root_mean_squared_error = np.sqrt(metrics.mean_squared_error(predictions, targets))\n",
    "\n",
    "    print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Final RMSE (on training data): 160.48\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=3,\n",
    "    batch_size=10,\n",
    "    input_features = ['housing_median_age','median_income','households']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)\n",
    "\n",
    "Вместо `tf.estimator.LinearRegressor` попробуйте применить другую модель и достигнуть $RMSE \\leq 160$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(learning_rate, num_epochs, batch_size, input_features=[\"total_rooms\"]):\n",
    "\n",
    "    my_feature_data = california_housing_dataframe[input_features]\n",
    "    targets = california_housing_dataframe[\"median_house_value\"]\n",
    "\n",
    "    # Create feature columns.\n",
    "    \n",
    "    feature_columns = [tf.feature_column.numeric_column(input_feature, shape=(1,)) for input_feature in input_features]\n",
    "\n",
    "    # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size, num_epochs=num_epochs)\n",
    "    prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "    # Create a linear regressor object.\n",
    "    my_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "    linear_regressor = tf.estimator.DNNRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer,\n",
    "      hidden_units=[3]\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    linear_regressor.train(input_fn=training_input_fn)\n",
    "\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "    root_mean_squared_error = np.sqrt(metrics.mean_squared_error(predictions, targets))\n",
    "\n",
    "    print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Final RMSE (on training data): 118.42\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=20,\n",
    "    batch_size=10,\n",
    "    input_features = ['housing_median_age','median_income','households']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JndnmDMp66FL",
    "ajVM7rkoYXeL",
    "ci1ISxxrZ7v0"
   ],
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
