{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План\n",
    "\n",
    "* Transfer learning/fine-tuning\n",
    "* ULMFiT\n",
    "* Tensorflow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning, Fine-Tuning\n",
    "### Идея\n",
    "\n",
    "Transfer learning -- область в глубинном обучении, которая изучает возможность применения знаний, полученных на решениии одной задачи, к другой.\n",
    "\n",
    "\n",
    "<img src=\"http://ruder.io/content/images/2017/03/traditional_ml_setup.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "\n",
    "### ImageNet\n",
    "\n",
    "[ImageNet](http://www.image-net.org/) is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images.\n",
    "\n",
    "\n",
    "<img src=\"http://ruder.io/content/images/2018/07/imagenet_challenge.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Liangpei_Zhang/publication/319148488/figure/fig1/AS:528165933195264@1502935979026/The-AlexNet-architecture-with-side-supervision-The-AlexNet-architecture-with-side.png\" width=\"500\">\n",
    "\n",
    "\n",
    "### VGG16\n",
    "\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\" width=\"500\">\n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2019/01/resnet-neural-e1548772388921.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналогия с крокодилом\n",
    "\n",
    "[Источник](https://github.com/yandexdataschool/Practical_DL/tree/spring2019/week04_finetuning) аналогии\n",
    "\n",
    "3 шага к успеху:\n",
    "\n",
    "1. Тренируем сеть на каком-нибудь датасете\n",
    "2. Отрезаем голову у этой сети, вставляем другую (используем тело в качестве feature extractor)\n",
    "3. Обучаем на другом датасете\n",
    "\n",
    "<img src=\"1.png\" width=\"500\">\n",
    "\n",
    "<img src=\"2.png\" width=\"500\">\n",
    "\n",
    "<img src=\"3.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained layers\n",
    "\n",
    "Мы надеемся, что сеть выучит полезные признаки, которые можно будет использовать на других задачах.\n",
    "\n",
    "<img src=\"http://ruder.io/content/images/2018/07/feature_visualization.png\" width=\"700\">\n",
    "\n",
    "[Distill link](https://distill.pub/2017/feature-visualization/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "## Проблемы\n",
    "\n",
    "1. Мало размеченных датасетов\n",
    "2. Разные языки\n",
    "\n",
    "\n",
    "## Word2vec\n",
    "\n",
    "Remember word2vec? Мы инициализируем матрицу эмбеддингов с помощью модели, обученной на большом неразмеченном корпусе.\n",
    "\n",
    "<img src=\"http://ruder.io/content/images/2018/07/word2vec_relations.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling\n",
    "\n",
    "В NLP есть огромные неразмеченные корпусы данных, которые можно использовать для предобучения.\n",
    "\n",
    "\n",
    "## ULMFiT\n",
    "\n",
    "Одной из статей, которая дала развитие transfer learning в NLP, была [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146)\n",
    "\n",
    "<img src=\"https://memegenerator.net/img/instances/84330585/pretrain-your-nlp-models-and-everybody-loses-their-minds.jpg\" width=\"500\">\n",
    "\n",
    "### Шаги к успеху\n",
    "\n",
    "1. Обучаем LM (AWD LSTM) модель на большом неразмеченном корпусе\n",
    "2. Дообучаем LM на нашем корпусе\n",
    "3. Переносим на другую задачу\n",
    "\n",
    "<img src=\"http://nlp.fast.ai/images/ulmfit_approach.png\" width=\"600\">\n",
    "<img src=\"http://ruder.io/content/images/2018/07/ulmfit.png\" width=\"600\">\n",
    "\n",
    "\n",
    "### Выводы\n",
    "\n",
    "* Нужно меньше данных для обучения\n",
    "* Быстрое схождение\n",
    "\n",
    "<img src=\"http://nlp.fast.ai/images/ulmfit_imdb.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика\n",
    "\n",
    "Попробуем решить [соревнование](https://www.kaggle.com/c/60k-classes-text-classification), которое было дано в качестве домашки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation=90):\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(\n",
    "      corr,\n",
    "      xticklabels=labels,\n",
    "      yticklabels=labels,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "      cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_string(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9]\", \" \", string)  \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../05_dssm/competition/train.csv')\n",
    "test = pd.read_csv('../05_dssm/competition/test_with_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x: tokenize_string(x))\n",
    "test['text'] = test['text'].apply(lambda x: tokenize_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_texts = test['text'].values\n",
    "train_texts = train['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Hub\n",
    "\n",
    "[TensorFlow Hub](https://www.tensorflow.org/hub) is a library for reusable machine learning modules.\n",
    "\n",
    "# Zero-Shot learning\n",
    "\n",
    "В качестве feature extractor мы будем использовать [Universal Sentence Encoder](https://arxiv.org/pdf/1803.11175.pdf)\n",
    "\n",
    "\n",
    "<img src=\"https://www.gstatic.com/aihub/tfhub/universal-sentence-encoder/example-similarity.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только позитивные примеры из трейна\n",
    "\n",
    "condition = train['labels'] != -1\n",
    "train_labels = train.loc[condition, 'labels'].values\n",
    "test_labels = test['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedder = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = embedder(train.loc[condition, 'text'].tolist())\n",
    "test_embeddings = embedder(test['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "\n",
    "    train_embeds = sess.run(train_embeddings)\n",
    "    test_embeds = sess.run(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeds.shape, test_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('train.npy', train_embeds)\n",
    "# np.save('test.npy', test_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_embeds = np.load('train.npy')\n",
    "test_embeds = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# индексируем\n",
    "index = nmslib.init()\n",
    "index.addDataPointBatch(train_embeds)\n",
    "index.createIndex(print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# предсказываем\n",
    "neighbors_distances = np.array(index.knnQueryBatch(test_embeds, k=1))\n",
    "\n",
    "neighbors = neighbors_distances[:, 0, :].astype(np.int32).flatten()\n",
    "distances = neighbors_distances[:, 1, :].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.max(), distances.min(), distances.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** Как выбрать порог?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = train_labels[neighbors]\n",
    "\n",
    "predicted_labels[distances > 0.15] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(test_labels, predicted_labels, average='micro')\n",
    "\n",
    "print(f'F1 score = {f1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на какие-нибудь примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_embeddings = test_embeds[:5]\n",
    "\n",
    "its_texts = test['text'].tolist()[:5]\n",
    "\n",
    "plot_similarity(its_texts, some_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_embeddings = test_embeds[test_labels == 9273]\n",
    "\n",
    "its_texts = test.loc[test_labels == 9273, 'text'].tolist()\n",
    "\n",
    "plot_similarity(its_texts, some_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем выборку\n",
    "\n",
    "pos_texts = train['text'][condition].values\n",
    "neg_texts = train['text'][~condition].values\n",
    "\n",
    "pos_pairs = pos_texts.reshape(-1, 2)\n",
    "neg_pairs = np.array(list(zip(pos_texts, np.random.choice(neg_texts, size=len(pos_texts)))))\n",
    "pairs = np.append(pos_pairs, neg_pairs, axis=0)\n",
    "labels = np.array([1] * len(pos_pairs) + [0] * len(neg_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "\n",
    "indexes = np.random.permutation(range(len(pairs)))[:num_samples]\n",
    "\n",
    "pairs = pairs[indexes]\n",
    "labels = labels[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pairs, columns=['q1', 'q2'])\n",
    "data['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, stratify=data['labels'], test_size=0.1, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(train, train[\"labels\"], num_epochs=3, shuffle=True)\n",
    "\n",
    "train_input_fn_pred = tf.estimator.inputs.pandas_input_fn(train, train[\"labels\"], shuffle=False)\n",
    "test_input_fn_pred = tf.estimator.inputs.pandas_input_fn(test, test[\"labels\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# используем простой DNN классифаер\n",
    "\n",
    "hub_module = 'https://tfhub.dev/google/universal-sentence-encoder/2'\n",
    "\n",
    "def train_and_evaluate_with_module(hub_module=hub_module, train_module=False):\n",
    "    q1 = hub.text_embedding_column(key=\"q1\", module_spec=hub_module, trainable=train_module)\n",
    "    q2 = hub.text_embedding_column(key=\"q2\", module_spec=hub_module, trainable=train_module)\n",
    "\n",
    "    estimator = tf.estimator.DNNClassifier(\n",
    "      hidden_units=[500, 100],\n",
    "      feature_columns=[q1, q2],\n",
    "      n_classes=2,\n",
    "      optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "    estimator.train(input_fn=train_input_fn)\n",
    "\n",
    "    train_eval_result = estimator.evaluate(input_fn=train_input_fn_pred)\n",
    "    test_eval_result = estimator.evaluate(input_fn=test_input_fn_pred)\n",
    "\n",
    "    training_set_accuracy = train_eval_result[\"accuracy\"]\n",
    "    test_set_accuracy = test_eval_result[\"accuracy\"]\n",
    "\n",
    "    metrics = {\n",
    "      \"Training accuracy\": training_set_accuracy,\n",
    "      \"Test accuracy\": test_set_accuracy\n",
    "    }\n",
    "    \n",
    "    return estimator, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение\n",
    "\n",
    "estimator, metrics = train_and_evaluate_with_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что вместо kNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказание\n",
    "\n",
    "train_pos_texts = train_texts[condition]\n",
    "\n",
    "num_examples = 10\n",
    "\n",
    "df = []\n",
    "\n",
    "for t in test_texts[:num_examples]:\n",
    "    df.extend([[t, k] for k in train_pos_texts])\n",
    "\n",
    "df = pd.DataFrame(df, columns=['q1', 'q2'])\n",
    "\n",
    "test_pred = tf.estimator.inputs.pandas_input_fn(df, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = estimator.predict(test_pred)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for p in tqdm(preds):\n",
    "    predictions.append(p['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for p in tqdm(preds):\n",
    "    predictions.append(p['probabilities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Neural Transfer Learning for Natural Language Processing](http://ruder.io/thesis/neural_transfer_learning_for_nlp.pdf)\n",
    "* [CS231n, Transfer Learning](http://cs231n.github.io/transfer-learning/)\n",
    "* [Introducing state of the art text classification](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)\n",
    "* [Transfer Learning - Machine Learning's Next Frontier](http://ruder.io/transfer-learning/)\n",
    "* [NLP's ImageNet moment has arrived](http://ruder.io/nlp-imagenet/index.html)\n",
    "* [Feature Visualization](https://distill.pub/2017/feature-visualization/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
