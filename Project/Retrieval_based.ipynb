{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorboard import summary as summary_lib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm_notebook,tqdm_pandas,tqdm\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import nltk\n",
    "\n",
    "import tf_metrics\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from multiprocessing import cpu_count, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm, ...)`.\n"
     ]
    }
   ],
   "source": [
    "tqdm_pandas(tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context,answer\n",
      " Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец.,Спасибо.\n",
      "Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец. Спасибо.,Приедь к нам в Мурманск пожалуйста.\n",
      "Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец. Спасибо.,Тебе платят за это?\n",
      "Ты просто большой молодец. Спасибо. Тебе платят за это?,\"За посты на Пикабу? Да, платят. Достаточно при написании поста всего лишь ..\"\n",
      "\"Спасибо. Тебе платят за это? За посты на Пикабу? Да, пл\n"
     ]
    }
   ],
   "source": [
    "with open('pikabu.csv') as f:\n",
    "    print(f.read(500))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('pikabu.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Ты...</td>\n",
       "      <td>Спасибо.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Ты ...</td>\n",
       "      <td>Приедь к нам в Мурманск пожалуйста.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Ты ...</td>\n",
       "      <td>Тебе платят за это?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ты просто большой молодец. Спасибо. Тебе платя...</td>\n",
       "      <td>За посты на Пикабу? Да, платят. Достаточно при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Спасибо. Тебе платят за это? За посты на Пикаб...</td>\n",
       "      <td>Не нажимается сук</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ты просто большой молодец. Спасибо. Тебе платя...</td>\n",
       "      <td>Лично Путин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Спасибо. Тебе платят за это? Лично Путин</td>\n",
       "      <td>дарт вейдар</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Ты...</td>\n",
       "      <td>ну всё, теперь можно не убирать за собой, Чист...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Ты ...</td>\n",
       "      <td>Зачем заминусили человека? Очевидная ирония же...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу.</td>\n",
       "      <td>Герой, про которого я бы читал комиксы от dc и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Ге...</td>\n",
       "      <td>да хотя бы от bubble студии)) но чет не пишут))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Гер...</td>\n",
       "      <td>может силами пикабу родится комикс, хехе)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Герой, про которого я бы читал комиксы от dc и...</td>\n",
       "      <td>Зовите Чилика...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>да хотя бы от bubble студии)) но чет не пишут)...</td>\n",
       "      <td>/@Chiliktolik , ищем автора комиксов про чисто...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Герой, про которого я бы читал комиксы от dc и...</td>\n",
       "      <td>Только комикс и может родится. Нет бы выйти да...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Гер...</td>\n",
       "      <td>ты в маске убираешь или она только для деавтор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Герой, про которого я бы читал комиксы от dc и...</td>\n",
       "      <td>маска только для фото</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>да хотя бы от bubble студии)) но чет не пишут)...</td>\n",
       "      <td>понятно. А так молодец).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Гер...</td>\n",
       "      <td>Реликтовый лес? G-unit не нашел случаем?)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Убрал 600 литров мусора в реликтовом лесу. Гер...</td>\n",
       "      <td>Нужно мерчендайз организовывать</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  \\\n",
       "0    Убрал 600 литров мусора в реликтовом лесу. Ты...   \n",
       "1   Убрал 600 литров мусора в реликтовом лесу. Ты ...   \n",
       "2   Убрал 600 литров мусора в реликтовом лесу. Ты ...   \n",
       "3   Ты просто большой молодец. Спасибо. Тебе платя...   \n",
       "4   Спасибо. Тебе платят за это? За посты на Пикаб...   \n",
       "5   Ты просто большой молодец. Спасибо. Тебе платя...   \n",
       "6            Спасибо. Тебе платят за это? Лично Путин   \n",
       "7    Убрал 600 литров мусора в реликтовом лесу. Ты...   \n",
       "8   Убрал 600 литров мусора в реликтовом лесу. Ты ...   \n",
       "9          Убрал 600 литров мусора в реликтовом лесу.   \n",
       "10   Убрал 600 литров мусора в реликтовом лесу. Ге...   \n",
       "11  Убрал 600 литров мусора в реликтовом лесу. Гер...   \n",
       "12  Герой, про которого я бы читал комиксы от dc и...   \n",
       "13  да хотя бы от bubble студии)) но чет не пишут)...   \n",
       "14  Герой, про которого я бы читал комиксы от dc и...   \n",
       "15  Убрал 600 литров мусора в реликтовом лесу. Гер...   \n",
       "16  Герой, про которого я бы читал комиксы от dc и...   \n",
       "17  да хотя бы от bubble студии)) но чет не пишут)...   \n",
       "18  Убрал 600 литров мусора в реликтовом лесу. Гер...   \n",
       "19  Убрал 600 литров мусора в реликтовом лесу. Гер...   \n",
       "\n",
       "                                               answer  \n",
       "0                                            Спасибо.  \n",
       "1                 Приедь к нам в Мурманск пожалуйста.  \n",
       "2                                 Тебе платят за это?  \n",
       "3   За посты на Пикабу? Да, платят. Достаточно при...  \n",
       "4                                   Не нажимается сук  \n",
       "5                                         Лично Путин  \n",
       "6                                         дарт вейдар  \n",
       "7   ну всё, теперь можно не убирать за собой, Чист...  \n",
       "8   Зачем заминусили человека? Очевидная ирония же...  \n",
       "9   Герой, про которого я бы читал комиксы от dc и...  \n",
       "10    да хотя бы от bubble студии)) но чет не пишут))  \n",
       "11          может силами пикабу родится комикс, хехе)  \n",
       "12                                   Зовите Чилика...  \n",
       "13  /@Chiliktolik , ищем автора комиксов про чисто...  \n",
       "14  Только комикс и может родится. Нет бы выйти да...  \n",
       "15  ты в маске убираешь или она только для деавтор...  \n",
       "16                              маска только для фото  \n",
       "17                           понятно. А так молодец).  \n",
       "18          Реликтовый лес? G-unit не нашел случаем?)  \n",
       "19                    Нужно мерчендайз организовывать  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context    21486165\n",
       "answer     21486162\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['context'].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = df_train['context'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21486165,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец.',\n",
       "       'Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец. Спасибо.',\n",
       "       'Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец. Спасибо.',\n",
       "       'Ты просто большой молодец. Спасибо. Тебе платят за это?',\n",
       "       'Спасибо. Тебе платят за это? За посты на Пикабу? Да, платят. Достаточно при написании поста всего лишь ..',\n",
       "       'Ты просто большой молодец. Спасибо. Тебе платят за это?',\n",
       "       'Спасибо. Тебе платят за это? Лично Путин',\n",
       "       ' Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец.',\n",
       "       'Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец. ну всё, теперь можно не убирать за собой, Чистомен спасёт!',\n",
       "       '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "       ' Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел!',\n",
       "       'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "       'Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут)) может силами пикабу родится комикс, хехе)',\n",
       "       'да хотя бы от bubble студии)) но чет не пишут)) может силами пикабу родится комикс, хехе) Зовите Чилика...',\n",
       "       'Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут)) может силами пикабу родится комикс, хехе)',\n",
       "       'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "       'Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут)) ты в маске убираешь или она только для деавторизации на фото?',\n",
       "       'да хотя бы от bubble студии)) но чет не пишут)) ты в маске убираешь или она только для деавторизации на фото? маска только для фото',\n",
       "       'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "       'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802d451bc38f4de5847efe2fe7d29eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'убирать_VERB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-b35a23888ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_prep_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-3c1650a2fc15>\u001b[0m in \u001b[0;36mtext_prep_tags\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprev_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mtext_id_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_id_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_word\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mid_text_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_id_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_word\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'убирать_VERB'"
     ]
    }
   ],
   "source": [
    "k = np.array(list(map(text_prep_tags,tqdm_notebook(context[:20]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_id_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 'убирать_VERB'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_text_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_ru = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_id_vocab == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca0518b24b14d31b6b309edc037c9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<lambda>() got an unexpected keyword argument 'voc_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a09c868c3133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_prep_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-ba7d6bfcdfe6>\u001b[0m in \u001b[0;36mindex_tokenizer\u001b[0;34m(tokenizer, corpus)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvoc_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvoc_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoc_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-ba7d6bfcdfe6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindex_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvoc_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvoc_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoc_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() got an unexpected keyword argument 'voc_set'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([' Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец.',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец. Спасибо.',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец. Спасибо.',\n",
       "        'Ты просто большой молодец. Спасибо. Тебе платят за это?',\n",
       "        'Спасибо. Тебе платят за это? За посты на Пикабу? Да, платят. Достаточно при написании поста всего лишь ..',\n",
       "        'Ты просто большой молодец. Спасибо. Тебе платят за это?',\n",
       "        'Спасибо. Тебе платят за это? Лично Путин',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец.',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Ты просто большой молодец. ну всё, теперь можно не убирать за собой, Чистомен спасёт!',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел!',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "        'Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут)) может силами пикабу родится комикс, хехе)',\n",
       "        'да хотя бы от bubble студии)) но чет не пишут)) может силами пикабу родится комикс, хехе) Зовите Чилика...',\n",
       "        'Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут)) может силами пикабу родится комикс, хехе)',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "        'Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут)) ты в маске убираешь или она только для деавторизации на фото?',\n",
       "        'да хотя бы от bubble студии)) но чет не пишут)) ты в маске убираешь или она только для деавторизации на фото? маска только для фото',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут))',\n",
       "        'Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут)) Слушай, приезжай в Кишинев, тут просто жопа в некоторых районах. Я помогу.',\n",
       "        'Герой, про которого я бы читал комиксы от dc или марвел! да хотя бы от bubble студии)) но чет не пишут)) Слушай, приезжай в Кишинев, тут просто жопа в некоторых районах. Я помогу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел!',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! На самом деле, это тот герой, которым ты тоже можешь стать, но этого не сделаешь. Тебе легче им просто восхищаться',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел!',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел!',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел!',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел! Парень то герой, а как звать тех, кто нагадил и не убрал за собой?',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел!',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Герой, про которого я бы читал комиксы от dc или марвел!',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Герой, которого мы не заслужили, но который нам необходим.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Сколько мешков надо увезти? Просто чтобы понимать, с прицепом ехать или без...',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Сколько мешков надо увезти? Просто чтобы понимать, с прицепом ехать или без... там 6 мешков.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. хорошая работа, а то бесят люди которые мусорят в лесах',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. хорошая работа, а то бесят люди которые мусорят в лесах Меня бесят все люди которые мусорят и не только в лесах. Особенно раздражает когда блядь в двух метрах от мусорки.',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. хорошая работа, а то бесят люди которые мусорят в лесах Меня бесят все люди которые мусорят и не только в лесах. Особенно раздражает когда блядь в двух метрах от мусорки.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Я ж говорил друзьям - Не убирайте, Читомен уберёт. - А они не верили!',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Я ж говорил друзьям - Не убирайте, Читомен уберёт. - А они не верили! Оставайся на месте. Мусорная инквизиция уже выехала за тобой.',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Я ж говорил друзьям - Не убирайте, Читомен уберёт. - А они не верили! Оставайся на месте. Мусорная инквизиция уже выехала за тобой.',\n",
       "        'Я ж говорил друзьям - Не убирайте, Читомен уберёт. - А они не верили! Оставайся на месте. Мусорная инквизиция уже выехала за тобой. Почему заранее не сообщаешь место проведения уборки? Я думаю везде найдутся желающие присоединиться.',\n",
       "        'Оставайся на месте. Мусорная инквизиция уже выехала за тобой. Почему заранее не сообщаешь место проведения уборки? Я думаю везде найдутся желающие присоединиться. Я могу чего то не знать, сорян. Только недавно вообще узнал о его существовании',\n",
       "        'Почему заранее не сообщаешь место проведения уборки? Я думаю везде найдутся желающие присоединиться. Я могу чего то не знать, сорян. Только недавно вообще узнал о его существовании По идее, желающие могут сами выбрать любое место уборки, какое только захотят, так что смысла в сообщении не много',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Я ж говорил друзьям - Не убирайте, Читомен уберёт. - А они не верили!'],\n",
       "       dtype=object),\n",
       " array(['Убрал 600 литров мусора в реликтовом лесу. Я ж говорил друзьям - Не убирайте, Читомен уберёт. - А они не верили! Мы всегда с пацанами так делаем! Не ну а хренли там урн нету!? Я чо! Должен этот мусор таскать туда сюда? Мне чо делать больше нечего?',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. А есть Настоящий ГРЯЗНОМЕН!? Типо прикинулся вывезти 600 литров мусора и раскидал их как было в то же место?',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. А есть Настоящий ГРЯЗНОМЕН!? Типо прикинулся вывезти 600 литров мусора и раскидал их как было в то же место? Где есть добро там есть зло же вроде?',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. А почему лес реликтовый?',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. А почему лес реликтовый? Потому что в нем растут реликтовые сосны. )',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. А почему лес реликтовый?',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. А почему лес реликтовый? Ну конечно же он не реликтовый. Это слово всюду пихают просто.',\n",
       "        'А почему лес реликтовый? Ну конечно же он не реликтовый. Это слово всюду пихают просто. Лес действительно реликтовый)',\n",
       "        'Ну конечно же он не реликтовый. Это слово всюду пихают просто. Лес действительно реликтовый) Как уроженец Миасса, должен Вас заверить, что лес не реликтовый)',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Почему без перчаток!?',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Я один заметил носки с сандалиями? Уверен, они дают какой-то эпический буст, иначе супергерой их не носил бы.',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Я один заметил носки с сандалиями? Уверен, они дают какой-то эпический буст, иначе супергерой их не носил бы. это кеды бро.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Что такое реликтовый лес?',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Что такое реликтовый лес? Лес состоящий из реликтовых деревьев)',\n",
       "        'Что такое реликтовый лес? Лес состоящий из реликтовых деревьев) Чистомен по выходным за кэпа подрабатывает?',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Что такое реликтовый лес? Лес состоящий из реликтовых деревьев)',\n",
       "        'Что такое реликтовый лес? Лес состоящий из реликтовых деревьев) Но сосна ни в коем случае не является реликтом.',\n",
       "        'Лес состоящий из реликтовых деревьев) Но сосна ни в коем случае не является реликтом. является)',\n",
       "        'Но сосна ни в коем случае не является реликтом. является) Ок, пойду диплом сдавать и 30 лет работы в лесу под хвост..',\n",
       "        'является) Ок, пойду диплом сдавать и 30 лет работы в лесу под хвост.. Ну с такой аргументацией мир ничего не потеряет',\n",
       "        'Но сосна ни в коем случае не является реликтом. является) Ок, пойду диплом сдавать и 30 лет работы в лесу под хвост..',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Что заставляет человека убирать мусор за другими свинами? Я ограничиваюсь тем что не сорю сам.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. /@chistomen , комрад а как там идёт борьба с незнакомой рекламой?',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Молодец, чо, я сам в Копейске живу земляк, засранцев у нас как гавна за старой баней...',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Где заказать такую маску?',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Где заказать такую маску? Это его лицо, маска «под ней».',\n",
       "        'Убрал 600 литров мусора в реликтовом лесу. Где заказать такую маску? Это его лицо, маска «под ней».',\n",
       "        ' Убрал 600 литров мусора в реликтовом лесу. Где заказать такую маску?',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.',\n",
       "        '  Убрал 600 литров мусора в реликтовом лесу.'], dtype=object)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split(context[:100], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_tokenizer(tokenizer, corpus):\n",
    "    #voc_set = set()\n",
    "    res = np.fromiter(map(tokenizer,tqdm_notebook(corpus[:20]),),dtype=str)\n",
    "    voc_set = np.unique(res)\n",
    "    print(voc_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fu(x):\n",
    "    return np.apply_along_axis(text_prep_tags,1,np.reshape(x,(-1,1)))\n",
    "        \n",
    "def parallelize(data):\n",
    "    partitions = 6\n",
    "    data_split = np.array_split(data, partitions)\n",
    "    pool = Pool(partitions)\n",
    "    #data = np.stack(pool.apply(np.apply_along_axis,text_prep_tags,1,np.reshape(data_split,(-1,1))))\n",
    "    data = np.concatenate(pool.map(fu,data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time np_context = parallelize(context[:2000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('np_context',np_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 225 ms, total: 2.23 s\n",
      "Wall time: 8.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np_context = np.apply_along_axis(text_prep_tags,1,np.reshape(context[:10000],(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['туалет_NOUN', 'уличный_ADJ', 'страна_NOUN', 'большой_ADJ',\n",
       "       'везде_ADV', 'канализация_NOUN', 'протягивать_VERB', 'канада_NOUN',\n",
       "       'сша_NOUN', 'мало_ADV', 'сказать_VERB', 'сильно_ADV',\n",
       "       'маленький_ADJ', 'сша_NOUN', 'канада_NOUN', 'везде_ADV',\n",
       "       'канализация_NOUN', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
       "      dtype='<U25')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_context[11313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del np_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.array([3,4,3,6])\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '4', '3', '6', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', ''], dtype='<U1')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.empty([400], dtype=\"str\")\n",
    "y[:r.shape[0]] = r\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id_vocab = {}\n",
    "id_text_vocab = {}\n",
    "prev_word = None\n",
    "\n",
    "def text_prep_tags(text):\n",
    "   \n",
    "    #print(text)\n",
    "    text = text[0]\n",
    "    upos_map = {'A':'ADJ','ADV':'ADV','ADVPRO':'ADV','ANUM':'ADJ','APRO':'DET','COM':'ADJ','CONJ':'SCON','INTJ':'INTJ','NONLEX':'X','NUM':'NUM','PART':'PART','PR':'ADP','S':'NOUN','SPRO':'PRON','UNKN':'X' ,'V':'VERB'}\n",
    "    text = text.lower()\n",
    "    result = np.array([])\n",
    "    \n",
    "    \n",
    "    # Убираем лишние символы\n",
    "    #text = re.sub(r'[;,]',r' ',text).strip()\n",
    "    text = re.sub(r'[^\\w\\s\\.]',r'',text).strip()   \n",
    "    #text = [token.text for token in razdel.tokenize(text)]\n",
    "    # Делаем лемматизацию       \n",
    "#     text = [lemma for lemma in mystem.lemmatize(text) if not lemma.isspace() and lemma not in sw_ru\n",
    "#             and lemma.strip() not in ['.','..','...']]\n",
    "    \n",
    "#     if id_text_vocab != {}:\n",
    "#         prev_word = id_text_vocab[max(id_text_vocab.keys())]\n",
    "#     else:       \n",
    "#         prev_word = None\n",
    "        \n",
    "    for item in mystem.analyze(text):\n",
    "      #  print(item)\n",
    "        token = None\n",
    "        if item.get('analysis'):\n",
    "            lemma = item['analysis'][0]['lex']\n",
    "            pos = re.split('[=,]', item['analysis'][0]['gr'])[0]\n",
    "            #and lemma not in sw_ru\n",
    "            if not lemma.isspace()  and lemma.strip() not in ['.','..','...'] and lemma not in sw_ru:\n",
    "     \n",
    "                token = f'{lemma}_{upos_map[pos]}'\n",
    "        else:\n",
    "            lem_text = item[\"text\"]\n",
    "            if not lem_text.isspace() and lem_text.strip() not in ['.','..','...'] and lem_text not in sw_ru:\n",
    "            \n",
    "                token = f'{lem_text}_UNKN'\n",
    "            \n",
    "        if token:    \n",
    "            #result.append(token)\n",
    "            result = np.append(result,token)\n",
    "            \n",
    "#             if prev_word:\n",
    "#                 text_id_vocab[token] = text_id_vocab[prev_word] + 1\n",
    "#                 id_text_vocab[text_id_vocab[prev_word] + 1] = token\n",
    "#             else:\n",
    "#                 text_vocab[token] = 4\n",
    "#                 id_text_vocab[4] = token\n",
    "#             prev_word = token\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Лемматизатор неправильно разбивает слова с дефисом, поэтому исправляем это\n",
    "#     if '-' in text:\n",
    "#         for l in range(len(text)):\n",
    "#             if text[l] == '-':\n",
    "#                 text[l] = f'{text[l-1]}-{text[l+1]}'\n",
    "#                 text[l-1] = text[l+1] = text[l]\n",
    "    zer = np.empty([400], dtype=\"<U25\")\n",
    "    zer[:result.shape[0]] = result\n",
    "    return zer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('../../model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100001/100001 [02:23<00:00, 698.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_token_text = df_train.loc[:100000,'context'].progress_apply(text_prep_tags)\n",
    "#test_token_text = df_test['text'].progress_apply(text_prep_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 148710/21486165 [03:47<8:19:13, 712.36it/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-787dacba18ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_token_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_prep_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;31m# Close bar and return pandas calculation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-10edf92feabb>\u001b[0m in \u001b[0;36mtext_prep_tags\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         prev_word = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0;31m#  print(item)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymystem3/mystem.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_analyze_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymystem3/mystem.py\u001b[0m in \u001b[0;36m_analyze_impl\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_procout_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_token_text = df_train['context'].progress_apply(text_prep_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_v = CountVectorizer(tokenizer=text_prep_tags)\n",
    "count_v.fit(tqdm_notebook(pd.concat([df_train['text'],df_test['text']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [None, None, None, None, None, None, None, Non...\n",
       "1         [None, None, None, None, None, None, None, Non...\n",
       "2         [None, None, None, None, None, None, None, Non...\n",
       "3         [т_NOUN, None, None, None, None, None, None, N...\n",
       "4         [None, None, None, None, None, None, None, Non...\n",
       "5         [т_NOUN, None, None, None, None, None, None, N...\n",
       "6         [None, None, None, None, None, None, None, Non...\n",
       "7         [None, None, None, None, None, None, None, Non...\n",
       "8         [None, None, None, None, None, None, None, Non...\n",
       "9         [None, None, None, None, None, None, None, Non...\n",
       "10        [None, None, None, None, None, None, None, Non...\n",
       "11        [None, None, None, None, None, None, None, Non...\n",
       "12        [г_NOUN, None, None, None, None, None, None, N...\n",
       "13        [д_NOUN, None, None, None, None, None, None, N...\n",
       "14        [г_NOUN, None, None, None, None, None, None, N...\n",
       "15        [None, None, None, None, None, None, None, Non...\n",
       "16        [г_NOUN, None, None, None, None, None, None, N...\n",
       "17        [д_NOUN, None, None, None, None, None, None, N...\n",
       "18        [None, None, None, None, None, None, None, Non...\n",
       "19        [None, None, None, None, None, None, None, Non...\n",
       "20        [None, None, None, None, None, None, None, Non...\n",
       "21        [None, None, None, None, None, None, None, Non...\n",
       "22        [г_NOUN, None, None, None, None, None, None, N...\n",
       "23        [г_NOUN, None, None, None, None, None, None, N...\n",
       "24        [None, None, None, None, None, None, None, Non...\n",
       "25        [None, None, None, None, None, None, None, Non...\n",
       "26        [None, None, None, None, None, None, None, Non...\n",
       "27        [None, None, None, None, None, None, None, Non...\n",
       "28        [None, None, None, None, None, None, None, Non...\n",
       "29        [None, None, None, None, None, None, None, Non...\n",
       "                                ...                        \n",
       "99971     [None, None, None, None, None, None, None, Non...\n",
       "99972     [None, None, None, None, None, None, None, Non...\n",
       "99973     [None, None, None, None, None, None, None, Non...\n",
       "99974     [р_NOUN, None, None, None, None, None, None, N...\n",
       "99975     [None, None, None, None, None, None, None, Non...\n",
       "99976     [None, None, None, None, None, None, None, Non...\n",
       "99977     [д_NOUN, None, None, None, None, None, None, N...\n",
       "99978     [т_NOUN, None, None, None, None, None, None, N...\n",
       "99979     [None, None, None, None, None, None, None, Non...\n",
       "99980     [н_NOUN, None, None, None, None, None, None, N...\n",
       "99981     [None, None, None, None, None, None, None, Non...\n",
       "99982     [None, None, None, None, None, None, None, Non...\n",
       "99983     [None, None, None, None, None, None, None, Non...\n",
       "99984     [н_NOUN, None, None, None, None, None, None, N...\n",
       "99985     [н_NOUN, None, None, None, None, None, None, N...\n",
       "99986     [None, None, None, None, None, None, None, Non...\n",
       "99987     [ч_NOUN, None, None, None, None, None, None, N...\n",
       "99988     [None, None, None, None, None, None, None, Non...\n",
       "99989     [н_NOUN, None, None, None, None, None, None, N...\n",
       "99990     [None, None, None, None, None, None, None, Non...\n",
       "99991     [ч_NOUN, None, None, None, None, None, None, N...\n",
       "99992     [None, None, None, None, None, None, None, Non...\n",
       "99993     [т_NOUN, None, None, None, None, None, None, N...\n",
       "99994     [н_NOUN, None, None, None, None, None, None, N...\n",
       "99995     [н_NOUN, None, None, None, None, None, None, N...\n",
       "99996     [н_NOUN, None, None, None, None, None, None, N...\n",
       "99997     [None, None, None, None, None, None, None, Non...\n",
       "99998     [None, None, None, None, None, None, None, Non...\n",
       "99999     [н_NOUN, None, None, None, None, None, None, N...\n",
       "100000    [None, None, None, None, None, None, None, Non...\n",
       "Name: context, Length: 100001, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
